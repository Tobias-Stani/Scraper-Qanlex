# üè°Ô∏è **Proyecto de Web Scraping Judicial**

## üìù **Descripci√≥n del Proyecto**
Herramienta automatizada para la extracci√≥n de datos de **expedientes judiciales** del sitio web del **Poder Judicial Nacional**, con almacenamiento en una base de datos **MySQL**.

---

## üóÇÔ∏è **Descripci√≥n Detallada de Scripts**

### 1. `scraper.py`
#### üõ†Ô∏è **Funcionalidad Principal**
- Automatiza la extracci√≥n de informaci√≥n de casos judiciales.

#### üöÄ **Acciones Espec√≠ficas**
- Navega al sitio web del **Poder Judicial Nacional**.
- Realiza b√∫squedas con el filtro de palabra clave **"residuos"**.
- Resuelve el **CAPTCHA** de forma **manual**.
- Extrae informaci√≥n detallada de cada expediente, incluyendo:
  - **N√∫mero de expediente**  
  - **Jurisdicci√≥n**  
  - **Dependencia**  
  - **Situaci√≥n actual**  
  - **Car√°tula** (descripci√≥n del caso)  
  - **Movimientos del expediente**  
  - **Actores y demandados**

#### üìÇ **Salida**
- Genera un archivo `expedientes.json` con todos los datos extra√≠dos.

---

### 2. `guardarDb.py`
#### üõ†Ô∏è **Funcionalidad Principal**
- Automatiza la carga de datos extra√≠dos en una base de datos **MySQL**.

#### üöÄ **Acciones Espec√≠ficas**
- Lee el archivo `expedientes.json`.
- Establece conexi√≥n con la base de datos **MySQL**.
- Inserta los datos en tres tablas relacionales:
  1. **`expedientes`**: Informaci√≥n general del caso.  
  2. **`movimientos`**: Historial de movimientos del expediente.  
  3. **`participantes`**: Listado de actores y demandados. 
- Elimina el archivo.
- Cierra la conexion.  

#### üîß **Procesamiento de Datos**
- Limpia y formatea las fechas.
- Maneja **transacciones SQL** para asegurar la integridad de los datos.
- Elimina el archivo JSON despu√©s de una carga exitosa.

---

### üìù **Correspondencia de los Datos Extra√≠dos con la Consigna**

A continuaci√≥n, se detalla c√≥mo cada campo extra√≠do por el scraper corresponde con los requisitos establecidos en la consigna del proyecto:

| **Campo Extra√≠do**      | **Descripci√≥n**                                                      | **Requisito de la Consigna**                              |
|-------------------------|----------------------------------------------------------------------|----------------------------------------------------------|
| **Expediente**           | N√∫mero √∫nico que identifica el expediente judicial.                  | El scraper extrae el n√∫mero del expediente judicial.      |
| **Dependencia**          | Dependencia judicial encargada de gestionar el expediente.           | Corresponde a la **Dependencia** del caso.                |
| **Demandante**           | Actores o personas que inician el caso judicial.                     | Extra√≠do como parte de los **actores** en el expediente.  |
| **Demandado**            | Personas o entidades contra las cuales se inicia el proceso judicial. | Extra√≠do como parte de los **demandados** en el expediente.|
| **Car√°tula**             | Breve descripci√≥n o resumen del caso judicial.                       | Corresponde a la **car√°tula** o descripci√≥n del caso.     |
| **Tipo de Demanda**      | Tipo de caso o acci√≥n legal (por ejemplo, "Acci√≥n Civil").            | Corresponde al **tipo de demanda** o acci√≥n judicial.     |
| **Juzgado o Tribunal**   | Juzgado o tribunal que est√° encargado del expediente.                 | Extra√≠do de la informaci√≥n de **jurisdicci√≥n** y **dependencia**. |
| **Fechas Relevantes**    | Fechas importantes asociadas al expediente (por ejemplo, fechas de audiencias, resoluciones). | Las **fechas** de los **movimientos** de cada expediente se extraen para registrar los eventos claves. |

---

## üîß **Requisitos Previos**
Antes de ejecutar el proyecto, aseg√∫rate de tener instalados:

- **Git**
- **Docker** y **Docker Compose**
- **Selenium**: Para la automatizaci√≥n del navegador.
- **Webdriver-Manager**: Gesti√≥n autom√°tica de **ChromeDriver**.
- **MySQL Connector for Python**: Para interactuar con la base de datos.

---

### üîç **Ejemplo de c√≥mo se extraen los datos**

- **Expediente**: El scraper extrae el n√∫mero de expediente judicial directamente de la p√°gina web del Poder Judicial Nacional.
- **Dependencia**: Se extrae de la jurisdicci√≥n correspondiente que lleva el caso.
- **Demandante y Demandado**: Los actores (demandantes) y demandados se extraen de las listas asociadas al expediente judicial.
- **Car√°tula**: Es la breve descripci√≥n del caso que se obtiene directamente de la informaci√≥n disponible en la p√°gina.
- **Tipo de Demanda**: Este dato es derivado de la descripci√≥n de la causa (car√°tula) y otras fuentes disponibles en el expediente.
- **Juzgado o Tribunal**: La jurisdicci√≥n y dependencia del caso indican el juzgado o tribunal que maneja el expediente.
- **Fechas Relevantes**: El scraper extrae las fechas de los movimientos del expediente, como resoluciones, audiencias, entre otros.

---

### üìÇ **Relaci√≥n con la Base de Datos**

- **Expediente**: Almacenado en la tabla `expedientes` en el campo `expediente`.
- **Dependencia**: Almacenado en la tabla `expedientes` en el campo `dependencia`.
- **Demandante y Demandado**: Almacenados en la tabla `participantes` con la informaci√≥n del `tipo` (actor o demandado) y `nombre`.
- **Car√°tula**: Almacenado en la tabla `expedientes` en el campo `caratula`.
- **Tipo de Demanda**: Este campo puede ser extra√≠do de la car√°tula o los movimientos, y se puede almacenar en el campo `situacion_actual` de la tabla `expedientes`.
- **Juzgado o Tribunal**: Extra√≠do de la jurisdicci√≥n, se almacena en la tabla `expedientes` en el campo `jurisdiccion`.
- **Fechas Relevantes**: Almacenadas en la tabla `movimientos`, con la fecha y el tipo de movimiento correspondiente.



## üöÄ **Pasos de Instalaci√≥n y Ejecuci√≥n**

1. **Clonar el repositorio**:  
   ```bash
   git clone https://github.com/Tobias-Stani/Scraper-Qanlex.git
   ```

2. **Moverse al directorio del proyecto**:  
   ```bash
   cd Scraper-Qanlex
   ```

3. **Construir la imagen de Docker**:  
   ```bash
   docker-compose build
   ```

4. **Levantar el contenedor**:  
   ```bash
   docker-compose up
   ```

5. **Instalar dependencias (local)**:  
   ```bash
   pip install selenium webdriver-manager mysql-connector-python
   ```

6. **Configurar conexi√≥n MySQL**:  
   - Verificar las credenciales y la IP del servidor en el archivo `docker-compose.yml`.
   - Configurar los datos de acceso en los scripts.

7. **Crear base de datos y estructura**:  
   Ejecutar la siguiente estructura SQL en MySQL:

   ```sql
    -- La tabla `expedientes` almacena informaci√≥n b√°sica del expediente judicial.
    CREATE TABLE expedientes (
        id INT AUTO_INCREMENT PRIMARY KEY,
        expediente VARCHAR(255),           -- El n√∫mero del expediente judicial
        jurisdiccion VARCHAR(255),         -- La jurisdicci√≥n del caso
        dependencia VARCHAR(255),          -- Dependencia que lleva el caso
        situacion_actual VARCHAR(255),     -- Estado o situaci√≥n actual del expediente
        caratula VARCHAR(255)              -- Descripci√≥n breve del caso
    );
    
    -- La tabla `movimientos` almacena los movimientos del expediente judicial.
    CREATE TABLE movimientos (
        id INT AUTO_INCREMENT PRIMARY KEY,
        expediente_id INT,                 -- Relacionado con el ID de la tabla `expedientes`
        fecha DATE,                        -- Fecha del movimiento
        tipo VARCHAR(255),                 -- Tipo de movimiento (ej. "Resoluci√≥n", "Audiencia", etc.)
        detalle TEXT,                      -- Descripci√≥n del movimiento
        FOREIGN KEY (expediente_id) REFERENCES expedientes(id) -- Relaci√≥n con `expedientes`
    );
    
    -- La tabla `participantes` almacena los actores y demandados en el expediente.
    CREATE TABLE participantes (
        id INT AUTO_INCREMENT PRIMARY KEY,
        expediente_id INT,                 -- Relacionado con el ID de la tabla `expedientes`
        tipo VARCHAR(255),                 -- Tipo de participante (actor, demandado, etc.)
        nombre VARCHAR(255),               -- Nombre del participante
        FOREIGN KEY (expediente_id) REFERENCES expedientes(id) -- Relaci√≥n con `expedientes`
    );
   ```

8. **Ejecutar los scripts**:  
   ```bash
   python scraper.py
   python guardarDb.py
   ```

---

## üí° **Posibles Mejoras**
1. **Optimizaci√≥n del script principal** para reducir los tiempos de ejecuci√≥n.  
2. Implementaci√≥n de **resoluci√≥n autom√°tica del CAPTCHA**.  
3. Mejor arquitectura para **AWS** con despliegue automatizado.  
4. Uso de **variables de entorno** para eliminar credenciales **hardcodeadas**.

---

## üîç **Detalles del Proyecto**

### üì¶ **Componentes**
- **`scraper.py`**: Extracci√≥n de datos judiciales.  
- **`guardarDb.py`**: Carga de datos en MySQL.  
- **Docker**: Infraestructura para facilitar el despliegue.

### üõ†Ô∏è **Tecnolog√≠as Utilizadas**
- **Python**
- **Selenium**
- **MySQL**
- **Docker**

---

## üö® **Consideraciones Importantes**

- **Resoluci√≥n Manual de CAPTCHA**: 
  - Durante la ejecuci√≥n del script `scraper.py`, se requiere intervenci√≥n manual para resolver el CAPTCHA. Aseg√∫rate de estar disponible para completar esta tarea cuando se te solicite.

- **Una vez resuelto el CAPTCHA**:
  - Una vez resuelto el CAPTCHA, el usuario no necesitar√° hacer nada m√°s. El proceso est√° completamente automatizado y el programa te indicar√° cualquier acci√≥n adicional que deba tomarse.
  
- **Conexi√≥n a Internet Estable**:
  - La herramienta depende de una conexi√≥n a internet para acceder al sitio web y obtener los datos. Aseg√∫rate de tener una conexi√≥n estable antes de ejecutar los scripts.

- **Instalaci√≥n de Google Chrome**:
  - Se debe tener **Google Chrome** instalado en la m√°quina host, ya que **Selenium** utiliza este navegador para la automatizaci√≥n.

- **Ejecutar el Script `scraper.py` Varias Veces**:
  - Es posible que necesites ejecutar el script `scraper.py` varias veces para asegurarte de que se obtengan todos los expedientes disponibles. Esto es especialmente √∫til si el n√∫mero de casos es grande y la b√∫squeda puede no devolver todos los resultados en una sola ejecuci√≥n.

- **Credenciales de Base de Datos**:
  - Aseg√∫rate de configurar correctamente las credenciales de acceso a la base de datos. Por defecto, las credenciales son las siguientes:
  
    ```bash
    DB_HOST=172.30.0.2
    DB_USER=scraperuser
    DB_PASSWORD=scraperpass
    DB_NAME=scraper_data
    ```

  - Verifica que estos valores coincidan con los configurados en tu entorno o en tu archivo `docker-compose.yml`.



